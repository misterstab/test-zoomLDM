black==23.7.0
chardet==5.1.0
einops>=0.6.1
fairscale>=0.4.13
fire>=0.5.0
fsspec>=2023.6.0
invisible-watermark>=0.2.0
kornia==0.6.9
matplotlib>=3.7.2
natsort>=8.4.0
ninja>=1.11.1
numpy==1.24.4
pyarrow==17.0.0
bitsandbytes==0.43.2
open-clip-torch>=2.20.0
opencv-python==4.6.0.66
pandas>=2.0.3
pillow>=9.5.0
pytorch-lightning==1.5.0
pyyaml>=6.0.1
scipy>=1.10.1
streamlit>=0.73.1
tensorboardx==2.6
timm>=0.9.2
tokenizers==0.12.1
torch==2.0.1
torchaudio>=2.0.2
torchdata==0.6.1
torchmetrics>=1.0.1
torchvision>=0.15.2
tqdm>=4.65.0
transformers==4.19.1
#triton==2.0.0
urllib3<1.27,>=1.25.4
webdataset>=0.2.33
wheel>=0.41.0
xformers>=0.0.20
streamlit-keyup==0.2.0
albumentations==0.4.3
pudb==2019.2
imageio==2.9.0
imageio-ffmpeg==0.4.2
omegaconf==2.1.1
test-tube>=0.7.5
pytorch-fid
wandb==0.15.4
h5py
huggingface_hub
datasets==3.0.2
taming-transformers-rom1504 
-e git+https://github.com/openai/CLIP.git@main#egg=clip
-e .